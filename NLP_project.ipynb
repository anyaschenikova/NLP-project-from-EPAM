{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NMvtkNcqEqwO"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Парсинг данных"
      ],
      "metadata": {
        "id": "wxrRamzSf_kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Панорама:"
      ],
      "metadata": {
        "id": "_RpxHnj5gw2Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "То, что парсила Аня"
      ],
      "metadata": {
        "id": "VyY28mRnkTFv"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfULSoSP2zx5"
      },
      "source": [
        "import requests, json, concurrent, pandas as pd\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "site_categories = []\n",
        "\n",
        "main_page_content = requests.get(f'https://panorama.pub').content\n",
        "bs_instance = BeautifulSoup(main_page_content, 'html.parser')\n",
        "useless_categories_links = ['/', '/books', '/donate', '/about']\n",
        "for nav_link in bs_instance.find_all('a', class_='nav-link'):\n",
        "  if nav_link['href'] in useless_categories_links:\n",
        "    continue\n",
        "  site_categories.append({\n",
        "      'link': nav_link['href'],\n",
        "      'name': nav_link.text.replace('\\n', '').strip()\n",
        "  })\n",
        "\n",
        "parsed_news = {site_category['name']: [] for site_category in site_categories}\n",
        "def get_pages(category, pages_amount, page_num):\n",
        "  print(f'Скачиваю страницу номер {page_num} из {pages_amount}')\n",
        "  page_content = requests.get(f'https://panorama.pub{category[\"link\"]}?page={page_num}').content\n",
        "\n",
        "  for news_link in BeautifulSoup(page_content, 'html.parser').find_all('a', class_='entry big'):\n",
        "    news_content = requests.get(f'https://panorama.pub{news_link[\"href\"]}').content\n",
        "    bs_instance = BeautifulSoup(news_content, 'html.parser')\n",
        "\n",
        "    news_obj = {\n",
        "        'title': bs_instance.find('h1').text.replace('\\n', '').strip(),\n",
        "        'text': ' '.join([tag.text for tag in bs_instance.find_all('p')]) \n",
        "    }\n",
        "    parsed_news[category['name']].append(news_obj)\n",
        "    print(news_obj['title'])\n",
        "\n",
        "\n",
        "for category in site_categories:\n",
        "  print('#' * 20)\n",
        "  print(f'Скачиваю категорию: {category[\"name\"]}')\n",
        "  category_content = requests.get(f'https://panorama.pub{category[\"link\"]}').content\n",
        "\n",
        "  bs_instance = BeautifulSoup(category_content, 'html.parser')\n",
        "  pages_amount = int(bs_instance.find('ul', class_='pagination').find_all('li')[-2].select('a')[0].text)\n",
        "  with concurrent.futures.ThreadPoolExecutor() as executor: # optimally defined number of threads\n",
        "    res = [executor.submit(get_pages, category, pages_amount, page_num) for page_num in range(1, pages_amount + 1)]\n",
        "    concurrent.futures.wait(res)\n",
        "      \n",
        "    # with open('/content/dump_articles.json', 'w') as f:\n",
        "    #   f.write(json.dumps(parsed_news))\n",
        "  print('#' * 20)\n",
        "\n",
        "data_list = []\n",
        "for category in site_categories:\n",
        "  for news in parsed_news[category['name']]:\n",
        "    data_list.append({\n",
        "      'Заголовок': news['title'],\n",
        "      'Текст': news['text'],\n",
        "       'Категория': category['name']\n",
        "    })\n",
        "pd.DataFrame(data_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w52bWSEYKSQo"
      },
      "source": [
        "pd.DataFrame(data_list).to_csv('/content/panorama_all.csv', encoding='utf-8', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Соединяем все в одно"
      ],
      "metadata": {
        "id": "HnkUqwJXkWe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "anna = pd.read_csv('/content/panorama_all.csv')"
      ],
      "metadata": {
        "id": "KL26rB1TkVyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gleb = pd.read_csv('economics.csv')\n",
        "for name in ['society.csv', 'articles.csv', 'politics.csv', 'books.csv', 'science.csv']:\n",
        "    buff = pd.read_csv(name)\n",
        "    gleb = pd.concat([gleb, buff])"
      ],
      "metadata": {
        "id": "h4eyK_V0kqGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n36GjL-tkKpe"
      },
      "outputs": [],
      "source": [
        "gleb = gleb.loc[:, ['Category', 'Header', 'Text']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qti0W_9JkKpe"
      },
      "outputs": [],
      "source": [
        "def tranform(x):\n",
        "    if x in ['«Экономика»', '«Общество»', '«Статьи»', '«Политика»', '«Книги»', '«Наука»']:\n",
        "        return str(x)[1:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbRQk5T9kKpf"
      },
      "outputs": [],
      "source": [
        "gleb.Category = list(map(tranform  , gleb.Category.tolist()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzUfn1h6kKpg",
        "outputId": "8222d3c6-c91d-451e-a466-8b30f008ac0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Series([], dtype: int64)\n"
          ]
        }
      ],
      "source": [
        "missing_val_count_by_column = (gleb.isnull().sum())\n",
        "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ux8rS_ykKpg"
      },
      "outputs": [],
      "source": [
        "gleb.dropna(inplace= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCTr_mDdkKpg",
        "outputId": "85cc248e-590a-4cd8-9ea7-54502776de22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Header</th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>В Берлине прошли народные гулянья в честь годо...</td>\n",
              "      <td>Более 4 тысяч берлинцев приняли участие в наро...</td>\n",
              "      <td>Политика</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Жители Бендер требуют переименования города</td>\n",
              "      <td>Более 20 тысяч жителей молдавского города Бенд...</td>\n",
              "      <td>Политика</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Меркель и Лукашенко договорились разделить Пол...</td>\n",
              "      <td>Врио канцлера ФРГ Ангела Меркель и Александр Л...</td>\n",
              "      <td>Политика</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Либерализация в КНДР: пограничники будут дават...</td>\n",
              "      <td>Лидер КНДР Ким Чен Ын объявил о том, что в рам...</td>\n",
              "      <td>Политика</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Пресс-служба президента предсказала серьёзные ...</td>\n",
              "      <td>На брифинге в пятницу пресс-секретарь президен...</td>\n",
              "      <td>Политика</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Header  \\\n",
              "0  В Берлине прошли народные гулянья в честь годо...   \n",
              "1        Жители Бендер требуют переименования города   \n",
              "2  Меркель и Лукашенко договорились разделить Пол...   \n",
              "3  Либерализация в КНДР: пограничники будут дават...   \n",
              "4  Пресс-служба президента предсказала серьёзные ...   \n",
              "\n",
              "                                                Text  Category  \n",
              "0  Более 4 тысяч берлинцев приняли участие в наро...  Политика  \n",
              "1  Более 20 тысяч жителей молдавского города Бенд...  Политика  \n",
              "2  Врио канцлера ФРГ Ангела Меркель и Александр Л...  Политика  \n",
              "3  Лидер КНДР Ким Чен Ын объявил о том, что в рам...  Политика  \n",
              "4  На брифинге в пятницу пресс-секретарь президен...  Политика  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "anna.rename(columns={'Заголовок': 'Header', 'Текст': 'Text', 'Категория': 'Category'}, inplace= True)\n",
        "anna.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7f6WKtjkKph",
        "outputId": "f5be8231-76dd-436e-cc8e-9aad3fb98f8f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(9097, 3)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = pd.concat([anna, gleb])\n",
        "dataset.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQP2uPWkkKpi"
      },
      "outputs": [],
      "source": [
        "dataset = dataset.sample(frac = 1)\n",
        "# dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Предобработка данных"
      ],
      "metadata": {
        "id": "66kkDoOxgzMx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Очистка данных"
      ],
      "metadata": {
        "id": "PePxAuY9nduw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "print(stopwords.words('russian'))"
      ],
      "metadata": {
        "id": "G3Vh11Xkc8kH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/dataset.csv')\n",
        "data"
      ],
      "metadata": {
        "id": "kR12k28Pdgsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.dropna(inplace=True)\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data"
      ],
      "metadata": {
        "id": "hSAmMewgdnSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "headings=list(data)"
      ],
      "metadata": {
        "id": "7DiDbtJNdpLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def f(data):\n",
        "  headings=list(data)\n",
        "  import nltk\n",
        "  nltk.download('stopwords')\n",
        "  from nltk.corpus import stopwords\n",
        "  print(stopwords.words('russian'))\n",
        "  from nltk.corpus import stopwords\n",
        "  from nltk.tokenize import word_tokenize\n",
        "  nltk.download('punkt')\n",
        "  stop_words = set(stopwords.words('russian'))\n",
        "  print(type(stop_words))\n",
        "  import re\n",
        "  for i in range(0, len(headings)):\n",
        "    for j in range(len(data)):\n",
        "      if type(data[headings[i]][j])==str:\n",
        "        data[headings[i]][j] = re.sub(\" +\", \" \", data[headings[i]][j])\n",
        "        data[headings[i]][j] = data[headings[i]][j].lower()\n",
        "        data[headings[i]][j] = re.sub(\"[^\\\\dа-я !.,?:;]\",\"\",data[headings[i]][j])\n",
        "        data[headings[i]][j] = re.sub(\" - \",\"\",data[headings[i]][j])\n",
        "        word_tokens = word_tokenize(data[headings[i]][j])\n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        data[headings[i]][j] = filtered_sentence"
      ],
      "metadata": {
        "id": "0I190vSmdsOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f(data)"
      ],
      "metadata": {
        "id": "U-QRz47xduZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Леммитизация"
      ],
      "metadata": {
        "id": "YzkXYKclnmHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmitization(words):\n",
        "  morph = pymorphy2.MorphAnalyzer()\n",
        "  words_lem = []\n",
        "  # print('Still working...')\n",
        "  for word in words:\n",
        "    words_lem.append(morph.parse(word)[0].normal_form)\n",
        "\n",
        "  return ' '.join(words_lem)\n",
        "\n",
        "for i in range(data.shape[0]):\n",
        "    data.loc[i, 'Text'] = lemmitization(data.loc[i, 'Text'].split(' '))"
      ],
      "metadata": {
        "id": "lqrRZKnQnibb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/mjybhw3t67wk6zi/data_lemm.csv?dl=0 -O data_lemm.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwF4vBRhFM8r",
        "outputId": "1607ed1b-e727-4bc8-d619-cdc0e8e04a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-15 22:41:10--  https://www.dropbox.com/s/mjybhw3t67wk6zi/data_lemm.csv?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.81.18, 2620:100:6035:18::a27d:5512\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.81.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/mjybhw3t67wk6zi/data_lemm.csv [following]\n",
            "--2021-12-15 22:41:11--  https://www.dropbox.com/s/raw/mjybhw3t67wk6zi/data_lemm.csv\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uc0d7b0c9be0564f1c3f71caab3d.dl.dropboxusercontent.com/cd/0/inline/Bb58QPAbBVDDAsNlF2n8HrMvk-DBZ5I8_L5GG30jKHIvDMrZA2WGHf3tQcVH-IY4XKzDeqjlui-Brcy63AI0HN4M996nxoF0OOu0wIozhqS5r6gAFoAvSUPq3f_joY5mCAf0tHDFJqLfG3BuhXuY6GXw/file# [following]\n",
            "--2021-12-15 22:41:11--  https://uc0d7b0c9be0564f1c3f71caab3d.dl.dropboxusercontent.com/cd/0/inline/Bb58QPAbBVDDAsNlF2n8HrMvk-DBZ5I8_L5GG30jKHIvDMrZA2WGHf3tQcVH-IY4XKzDeqjlui-Brcy63AI0HN4M996nxoF0OOu0wIozhqS5r6gAFoAvSUPq3f_joY5mCAf0tHDFJqLfG3BuhXuY6GXw/file\n",
            "Resolving uc0d7b0c9be0564f1c3f71caab3d.dl.dropboxusercontent.com (uc0d7b0c9be0564f1c3f71caab3d.dl.dropboxusercontent.com)... 162.125.7.15, 2620:100:6035:15::a27d:550f\n",
            "Connecting to uc0d7b0c9be0564f1c3f71caab3d.dl.dropboxusercontent.com (uc0d7b0c9be0564f1c3f71caab3d.dl.dropboxusercontent.com)|162.125.7.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21002187 (20M) [text/plain]\n",
            "Saving to: ‘data_lemm.csv’\n",
            "\n",
            "data_lemm.csv       100%[===================>]  20.03M  10.7MB/s    in 1.9s    \n",
            "\n",
            "2021-12-15 22:41:14 (10.7 MB/s) - ‘data_lemm.csv’ saved [21002187/21002187]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "juVRDNXhEqwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "outputId": "119b6665-d7d4-4085-9753-1a88e8da7bd1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>Header</th>\n",
              "      <th>Text</th>\n",
              "      <th>Category</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4175</td>\n",
              "      <td>«Я рада, что помогла вам обрести надежду и под...</td>\n",
              "      <td>приятный сюрприз новый год зритель решить сдел...</td>\n",
              "      <td>Общество</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2138</td>\n",
              "      <td>«Первый канал» проведёт телемарафон для спасен...</td>\n",
              "      <td>первый канал декабрь провести благотворительны...</td>\n",
              "      <td>Общество</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>161</td>\n",
              "      <td>Навального перевели в ШИЗО на  дня за татуиров...</td>\n",
              "      <td>блогер алексей навальный отбывать срок исправи...</td>\n",
              "      <td>Политика</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8525</td>\n",
              "      <td>По итогам года Беларусь импортировала из РФ тр...</td>\n",
              "      <td>итог месяц  год республика беларусь импортиров...</td>\n",
              "      <td>Экономика</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4062</td>\n",
              "      <td>В Сколково разработали умный автоответчик для ...</td>\n",
              "      <td>российский программист совместно инженер иннов...</td>\n",
              "      <td>Общество</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9090</th>\n",
              "      <td>9090</td>\n",
              "      <td>9092</td>\n",
              "      <td>8485</td>\n",
              "      <td>В Tesla появится автопилот, способный ездить п...</td>\n",
              "      <td>автоконцерн tesla планировать выпуск новый мод...</td>\n",
              "      <td>Экономика</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9091</th>\n",
              "      <td>9091</td>\n",
              "      <td>9093</td>\n",
              "      <td>8264</td>\n",
              "      <td>Во французской палате мер и весов появится эта...</td>\n",
              "      <td>международный бюро вес франция сообщить появле...</td>\n",
              "      <td>Наука</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9092</th>\n",
              "      <td>9092</td>\n",
              "      <td>9094</td>\n",
              "      <td>4596</td>\n",
              "      <td>ЦРУ: «Навальный не работает на нас. Он уволилс...</td>\n",
              "      <td>представитель центральный разведывательный упр...</td>\n",
              "      <td>Общество</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9093</th>\n",
              "      <td>9093</td>\n",
              "      <td>9095</td>\n",
              "      <td>5910</td>\n",
              "      <td>Москвичи подожгли мусорный полигон, дождавшись...</td>\n",
              "      <td>московский область февраль группа экстремистск...</td>\n",
              "      <td>Общество</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9094</th>\n",
              "      <td>9094</td>\n",
              "      <td>9096</td>\n",
              "      <td>5233</td>\n",
              "      <td>Издатель новой конституции подаст в суд на рос...</td>\n",
              "      <td>общероссийский голосование оставаться нескольк...</td>\n",
              "      <td>Общество</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9095 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Unnamed: 0  Unnamed: 0.1  ...   Category class\n",
              "0              0             0  ...   Общество     0\n",
              "1              1             1  ...   Общество     0\n",
              "2              2             2  ...   Политика     1\n",
              "3              3             3  ...  Экономика     2\n",
              "4              4             4  ...   Общество     0\n",
              "...          ...           ...  ...        ...   ...\n",
              "9090        9090          9092  ...  Экономика     2\n",
              "9091        9091          9093  ...      Наука     3\n",
              "9092        9092          9094  ...   Общество     0\n",
              "9093        9093          9095  ...   Общество     0\n",
              "9094        9094          9096  ...   Общество     0\n",
              "\n",
              "[9095 rows x 7 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data = pd.read_csv('/content/data_lemm.csv')\n",
        "# data.dropna(inplace=True)\n",
        "# data.reset_index(drop=True, inplace=True)\n",
        "# data.replace('\\d+', '', regex=True, inplace=True)\n",
        "# data.replace(\"^a-zA-Z0-9]+\", \"\", regex=True, inplace=True)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRPBHxDWEqwQ"
      },
      "outputs": [],
      "source": [
        "# data['class'] = 0\n",
        "# data.loc[data['Category'] == 'Политика', 'class'] = 1\n",
        "# data.loc[data['Category'] == 'Экономика', 'class'] = 2\n",
        "# data.loc[data['Category'] == 'Наука', 'class'] = 3\n",
        "# data.loc[data['Category'] == 'Статьи', 'class'] = 4\n",
        "# data.loc[data['Category'] == 'Книги', 'class'] = 5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkYjekWZEqwR"
      },
      "outputs": [],
      "source": [
        "data.to_csv('./data_lemm.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Векторизация"
      ],
      "metadata": {
        "id": "elGncQYaRALM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TF/IDF"
      ],
      "metadata": {
        "id": "1hvrSogfLnOd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIpPZ1YwEqwR"
      },
      "outputs": [],
      "source": [
        "def tfidf(texts):\n",
        "\n",
        "    corpus = texts.to_numpy()\n",
        "    \n",
        "    vocabulary = list(set([item for sublist in list(data['Text'].astype(str)) for item in sublist.split()]))\n",
        "    pipe = Pipeline([('count', CountVectorizer(vocabulary=vocabulary)),\n",
        "                    ('tfid', TfidfTransformer())]).fit(corpus)\n",
        "    pipe['count'].transform(corpus).toarray()\n",
        "    pipe['tfid'].idf_\n",
        "\n",
        "    return pipe.transform(corpus)\n",
        "\n",
        "test_tfidf = tfidf(data['Text'].astype(str))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Bag of Words:"
      ],
      "metadata": {
        "id": "uS18lDdPOihW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24kSA-CaEqwT"
      },
      "outputs": [],
      "source": [
        "def corpuses_embedding_count_vectorize(texts):\n",
        "\n",
        "    corpus = texts.to_numpy()\n",
        "    vectorizer = CountVectorizer()\n",
        "    X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "    return X.toarray()\n",
        "\n",
        "test_bow = corpuses_embedding_count_vectorize(data['Text'].astype(str))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Doc2Vec:"
      ],
      "metadata": {
        "id": "-pbJNvm0Oe1-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XgHPpyPvEqwU"
      },
      "outputs": [],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "def doc_to_vec(texts):\n",
        "    #tokenize and tag the card text\n",
        "    card_docs = [TaggedDocument(doc.split(' '), [i]) \n",
        "             for i, doc in enumerate(data['Text'].astype(str))]\n",
        "\n",
        "    model = Doc2Vec(vector_size=64, window=2, min_count=1, workers=8, epochs = 40)\n",
        "    #build vocab\n",
        "    model.build_vocab(card_docs)\n",
        "    #train model\n",
        "    model.train(card_docs, total_examples=model.corpus_count\n",
        "                , epochs=model.epochs)\n",
        "\n",
        "    card2vec = [model.infer_vector((texts[i].split(' '))) \n",
        "            for i in range(0,len(texts))]\n",
        "    \n",
        "    dtv= np.array(card2vec).tolist()\n",
        "\n",
        "    return dtv\n",
        "\n",
        "test_doc2vec = doc_to_vec(data['Text'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE-IvCoIEqwU"
      },
      "source": [
        "Fast Text не надо"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhIMyOBhEqwW"
      },
      "outputs": [],
      "source": [
        "from gensim.models.fasttext import FastText\n",
        "\n",
        "def ft(texts):\n",
        "\n",
        "\n",
        "    embedding_size = 60\n",
        "    window_size = 40\n",
        "    min_word = 5\n",
        "    down_sampling = 1e-2\n",
        "\n",
        "    ft_model = FastText(texts,\n",
        "                        size=embedding_size,\n",
        "                        window=window_size,\n",
        "                        min_count=min_word,\n",
        "                        sample=down_sampling,\n",
        "                        sg=1,\n",
        "                        iter=1)\n",
        "    \n",
        "    return np.array([[ft_model.wv[word] for word in text] for text in data['Text']])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучаем классификатор\n",
        "Смотрим по метрике F1-score"
      ],
      "metadata": {
        "id": "asl6xNOcGB8a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорты:"
      ],
      "metadata": {
        "id": "imp8wdoGF9ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "wmfbQ4KnFlzk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция обучения:"
      ],
      "metadata": {
        "id": "8Ve55aKzFarV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, X, y): \n",
        "  # тут разбиваем на train/test\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "  # учим\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  # и можно еще принтануть F1_score внутри\n",
        "  print(\"F1 score = \", f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "  # возвращаем y_test y_pred\n",
        "  return [y_test, y_pred, f1_score(y_test, y_pred, average='weighted')]"
      ],
      "metadata": {
        "id": "LhQoQ91wFcXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Байесовский классификатор"
      ],
      "metadata": {
        "id": "ZD_fWqbqIswj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gnb = GaussianNB()"
      ],
      "metadata": {
        "id": "kjSP0Vo7H4N1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc2Vec:"
      ],
      "metadata": {
        "id": "6CAL-QT9OJ4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2v = train(gnb, test_doc2vec, data['class']) "
      ],
      "metadata": {
        "id": "7mM1iRN2IOd9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88cb3bae-5f9a-4439-cfd2-708af1a3078a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 score =  0.7057905914961834\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF/IDF:"
      ],
      "metadata": {
        "id": "ycVQfq6kOM3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = train(gnb, test_tfidf.toarray(), data['class'])"
      ],
      "metadata": {
        "id": "ce-WQOdIIFum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of words:"
      ],
      "metadata": {
        "id": "0rnQWCaaOc1G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow = train(gnb, test_bow, data['class'])"
      ],
      "metadata": {
        "id": "RQmXAUT1OSbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(np.array([['d2v', 'tfidf', 'bow'], ['naive_bayes', 'naive_bayes', 'naive_bayes'], [d2v[2], tfidf[2], bow[2]]]),\n",
        "                   columns=['preprocess', 'model', 'f1 score'])\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "id": "xX1K8PlUPULx",
        "outputId": "599d5e6c-9565-463a-8cfe-4226f17f2336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-807d98141820>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df2 = pd.DataFrame(np.array([['d2v', 'tfidf', 'bow'], ['naive_bayes', 'naive_bayes', 'naive_bayes'], [d2v[2], tfidf[2], bow[2]]]),\n\u001b[0m\u001b[1;32m      2\u001b[0m                    columns=['preprocess', 'model', 'f1 score'])\n",
            "\u001b[0;31mNameError\u001b[0m: name 'd2v' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Random Forest"
      ],
      "metadata": {
        "id": "crCY527KhOzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rfc = RandomForestClassifier()"
      ],
      "metadata": {
        "id": "Vn6OKlCaQLXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc2Vec"
      ],
      "metadata": {
        "id": "xpN_4jBRhWpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2v_rfc = train(rfc, test_doc2vec, data['class'])"
      ],
      "metadata": {
        "id": "3Y262jvWhUjt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF/IDF:"
      ],
      "metadata": {
        "id": "3gGIV7kfhaLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_rfc = train(rfc, test_tfidf.toarray(), data['class'])"
      ],
      "metadata": {
        "id": "BIXhqPGDhaS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of words:"
      ],
      "metadata": {
        "id": "XtoHezUNheP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_rfc = train(rfc, test_bow, data['class'])"
      ],
      "metadata": {
        "id": "oLIxeZgKheXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_rfc = pd.DataFrame(np.array([['d2v_rfc', 'tfidf_rfc', 'bow_rfc'], ['random_forest', 'random_forest', 'random_forest'], [d2v_rfc[2], tfidf_rfc[2], bow_rfc[2]]]),\n",
        "                   columns=['preprocess', 'model', 'f1 score'])\n",
        "df_rfc"
      ],
      "metadata": {
        "id": "Lq_TgKVshifS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN"
      ],
      "metadata": {
        "id": "Uk5Ih5-4hi_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "Iz2AXow8hnTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc2Vec"
      ],
      "metadata": {
        "id": "YOjMlW8khmIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2v_knn = train(knn, test_doc2vec, data['class'])"
      ],
      "metadata": {
        "id": "L0DxhuTwhkYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF/IDF:"
      ],
      "metadata": {
        "id": "Z6-2URl7iPsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_knn = train(knn, test_tfidf.toarray(), data['class'])"
      ],
      "metadata": {
        "id": "i8jgJXoAiRTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of words:"
      ],
      "metadata": {
        "id": "b35Hm7x_iU7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_knn = train(knn, test_bow, data['class'])"
      ],
      "metadata": {
        "id": "ZHlhJUMciWnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_knn = pd.DataFrame(np.array([['d2v_knn', 'tfidf_knn', 'bow_knn'], ['knn', 'knn', 'knn'], [d2v_knn[2], tfidf_knn[2], bow_knn[2]]]),\n",
        "                   columns=['preprocess', 'model', 'f1 score'])\n",
        "df_knn"
      ],
      "metadata": {
        "id": "vtEJUDpviax1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SVM"
      ],
      "metadata": {
        "id": "M2yhYJrRc2Id"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svc = SVC()"
      ],
      "metadata": {
        "id": "XqsNHrr4dTGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Doc2Vec"
      ],
      "metadata": {
        "id": "AYwKY7eNdjx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2v_svc = train(svc, test_doc2vec, data['class'])"
      ],
      "metadata": {
        "id": "d8RemvKhdzEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF/IDF:"
      ],
      "metadata": {
        "id": "Cq3dIj08c78u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_svc = train(svc, test_tfidf.toarray(), data['class'])"
      ],
      "metadata": {
        "id": "USE7ua33dxgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of words:"
      ],
      "metadata": {
        "id": "pc9mNQCGeDoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bow_svc = train(svc, test_svc, data['class'])"
      ],
      "metadata": {
        "id": "I301T9kzd_NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_svc = pd.DataFrame(np.array([['d2v_svc', 'tfidf_svc', 'bow_svc'], ['svc', 'svc', 'svc'], [d2v_svc[2], tfidf_svc[2], bow_svc[2]]]),\n",
        "                   columns=['preprocess', 'model', 'f1 score'])\n",
        "df_svc"
      ],
      "metadata": {
        "id": "fQ4qyD-cd_0T"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.9 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "NLP project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}